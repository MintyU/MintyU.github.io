{"componentChunkName":"component---src-templates-post-tsx","path":"/Pytorch07/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"word2vec-실습en\" style=\"position:relative;\"><a href=\"#word2vec-%EC%8B%A4%EC%8A%B5en\" aria-label=\"word2vec 실습en permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word2Vec 실습(EN)</h2>\n<p>영어 데이터를 통해 Word2Vec을 학습시켜보도록 하겠습니다. <code class=\"language-text\">gensim</code>이라는 파이썬 패키지에 Word2Vec이 이미 구현되어 있으므로, 우리는 이를 따로 구현할 필요 없이 Word2Vec을 사용할 수 있습니다.</p>\n<p>우선 필요한 도구들을 import해주겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> nltk\nnltk<span class=\"token punctuation\">.</span>download<span class=\"token punctuation\">(</span><span class=\"token string\">'punkt'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> urllib<span class=\"token punctuation\">.</span>request\n<span class=\"token keyword\">import</span> zipfile\n<span class=\"token keyword\">from</span> lxml <span class=\"token keyword\">import</span> etree\n<span class=\"token keyword\">import</span> re\n<span class=\"token keyword\">from</span> nltk<span class=\"token punctuation\">.</span>tokenize <span class=\"token keyword\">import</span> word_tokenize<span class=\"token punctuation\">,</span> sent_tokenize</code></pre></div>\n<h3 id=\"훈련-데이터\" style=\"position:relative;\"><a href=\"#%ED%9B%88%EB%A0%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0\" aria-label=\"훈련 데이터 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>훈련 데이터</h3>\n<p>사용할 훈련 데이터는, ted 영상들의 자막 데이터입니다. 파일의 형식은 xml 파일입니다.</p>\n<p><a href=\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&#x26;filename=ted_en-20160408.zip\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">해당 링크</a>를 통해 내려받고 압축을 풀어서 <code class=\"language-text\">ted_en-20160408.xml</code>라는 이름의 파일을 설치할 수도 있고, 파이썬 코드를 통해 자동으로 설치할 수도 있습니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 다운로드</span>\nurllib<span class=\"token punctuation\">.</span>request<span class=\"token punctuation\">.</span>urlretrieve<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\"</span><span class=\"token punctuation\">,</span> filename<span class=\"token operator\">=</span><span class=\"token string\">\"ted_en-20160408.xml\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/>\n위의 코드를 통해 xml 파일을 내려받으면, 다음과 같은 파일을 볼 수 있습니다.\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token prolog\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>xml</span> <span class=\"token attr-name\">language</span><span class=\"token attr-value\"><span class=\"token punctuation attr-equals\">=</span><span class=\"token punctuation\">\"</span>en<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>file</span> <span class=\"token attr-name\">id</span><span class=\"token attr-value\"><span class=\"token punctuation attr-equals\">=</span><span class=\"token punctuation\">\"</span>1<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>head</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>url</span><span class=\"token punctuation\">></span></span>http://www.ted.com/talks/knut_haanaes_two_reasons_companies_fail_and_how_to_avoid_them<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>url</span><span class=\"token punctuation\">></span></span>\n\n    ...\n\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>content</span><span class=\"token punctuation\">></span></span>Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n\n    ...\n\n    So let me leave you with this. Whether you're an explorer by nature or whether you tend to exploit what you already know, don't forget: the beauty is in the balance.\n    Thank you.\n    (Applause)<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>content</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>file</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>file</span> <span class=\"token attr-name\">id</span><span class=\"token attr-value\"><span class=\"token punctuation attr-equals\">=</span><span class=\"token punctuation\">\"</span>2<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>head</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>url</span><span class=\"token punctuation\">></span></span>http://www.ted.com/talks/lisa_nip_how_humans_could_evolve_to_survive_in_space<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>url</span><span class=\"token punctuation\">></span></span>\n    \n    ...\n\n    (Applause)<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>content</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>file</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>xml</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<h3 id=\"전처리\" style=\"position:relative;\"><a href=\"#%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>전처리</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">targetXML<span class=\"token operator\">=</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'ted_en-20160408.xml'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'UTF8'</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># xml 파일과 python 실행 위치가 같은 경로일 경우의 코드!</span>\ntarget_text <span class=\"token operator\">=</span> etree<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>targetXML<span class=\"token punctuation\">)</span>\nparse_text <span class=\"token operator\">=</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>target_text<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'//content/text()'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># xml 파일로부터 &lt;content>와 &lt;/content> 사이의 내용만 가져온다.</span>\n\ncontent_text <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">r'\\([^)]*\\)'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span> parse_text<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.</span>\n<span class=\"token comment\"># 해당 코드는 괄호로 구성된 내용을 제거.</span>\n\nsent_text <span class=\"token operator\">=</span> sent_tokenize<span class=\"token punctuation\">(</span>content_text<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.</span>\n\nnormalized_text <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> string <span class=\"token keyword\">in</span> sent_text<span class=\"token punctuation\">:</span>\n     tokens <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">r\"[^a-z0-9]+\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> string<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n     normalized_text<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.</span>\n\nresult <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\nresult <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>word_tokenize<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> normalized_text<span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.</span></code></pre></div>\n<p>전처리 과정 후, 샘플의 수를 출력하면 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'총 샘플의 개수 : {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">총 샘플의 개수 : 273424</code></pre></div>\n<p>전처리가 되었으니, 이제 Word2Vec을 통해 텍스트 데이터를 학습시켜줍니다.</p>\n<h3 id=\"word2vec-학습\" style=\"position:relative;\"><a href=\"#word2vec-%ED%95%99%EC%8A%B5\" aria-label=\"word2vec 학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word2Vec 학습</h3>\n<p>Word2Vec 훈련에 앞서, gensim 모듈이 없다면 설치해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pip install gensim</code></pre></div>\n<br/>\n설치가 완료되었다면, 아래의 코드를 통해 아까 전처리한 데이터를 Word2Vec 모델로 학습시켜줍니다.\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> gensim<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Word2Vec<span class=\"token punctuation\">,</span> KeyedVectors\nmodel <span class=\"token operator\">=</span> Word2Vec<span class=\"token punctuation\">(</span>sentences<span class=\"token operator\">=</span>result<span class=\"token punctuation\">,</span> vector_size<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> window<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> min_count<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> workers<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> sg<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>여기서 Word2Vec의 하이퍼파라미터값은 다음과 같습니다.</p>\n<ul>\n<li><strong>vector_size</strong> = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.</li>\n<li><strong>window</strong> = 컨텍스트 윈도우 크기</li>\n<li><strong>min_count</strong> = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)</li>\n<li><strong>workers</strong> = 학습을 위한 프로세스 수</li>\n<li><strong>sg</strong> = 0은 CBOW, 1은 Skip-gram.</li>\n</ul>\n<p>Word2Vec에 대해서 학습을 진행하였습니다. Word2Vec는 입력한 단어에 대해서 가장 유사한 단어들을 출력하는 <code class=\"language-text\">model.wv.most_similar</code>을 지원합니다. </p>\n<p>earth와 유사한 단어는 어떤 것들이 있을까요?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model_result <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>most_similar<span class=\"token punctuation\">(</span><span class=\"token string\">\"earth\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model_result<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[(&#39;planet&#39;, 0.8294868469238281), \n(&#39;mars&#39;, 0.7876790165901184), \n(&#39;surface&#39;, 0.683158278465271), \n(&#39;sun&#39;, 0.6683340072631836), \n(&#39;ocean&#39;, 0.6607442498207092), \n(&#39;moon&#39;, 0.6605572700500488), \n(&#39;continent&#39;, 0.6459723711013794), \n(&#39;universe&#39;, 0.6119515895843506), \n(&#39;galaxy&#39;, 0.6062458753585815), \n(&#39;orbit&#39;, 0.6049789786338806)]</code></pre></div>\n<p>earth와 유사한 단어로 planet, mars, surface, sun 등 정말 그럴싸한 단어들을 내놓는 것을 볼 수 있었습니다.</p>\n<h3 id=\"모델-저장-로드\" style=\"position:relative;\"><a href=\"#%EB%AA%A8%EB%8D%B8-%EC%A0%80%EC%9E%A5-%EB%A1%9C%EB%93%9C\" aria-label=\"모델 저장 로드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>모델 저장, 로드</h3>\n<p>이렇게 학습시킨 Word2Vec 모델은 저장해두었다가 나중에 다시 로드해서 사용할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>save_word2vec_format<span class=\"token punctuation\">(</span><span class=\"token string\">'./eng_w2v'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모델 저장</span>\nloaded_model <span class=\"token operator\">=</span> KeyedVectors<span class=\"token punctuation\">.</span>load_word2vec_format<span class=\"token punctuation\">(</span><span class=\"token string\">\"eng_w2v\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모델 로드</span></code></pre></div>\n<br/>\n<p>위의 <code class=\"language-text\">loaded_model</code>은 앞선 예제의 <code class=\"language-text\">model.wv</code> 변수와 동일하게 사용하면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model_result <span class=\"token operator\">=</span> loaded_model<span class=\"token punctuation\">.</span>most_similar<span class=\"token punctuation\">(</span><span class=\"token string\">\"earth\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model_result<span class=\"token punctuation\">)</span></code></pre></div>","excerpt":"Word2Vec 실습(EN) 영어 데이터를 통해 Word2Vec을 학습시켜보도록 하겠습니다. 이라는 파이썬 패키지에 Word2Vec이 이미 구현되어 있으므로, 우리는 이를 따로 구현할 필요 없이 Word2Vec…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/Pytorch07/#word2vec-%EC%8B%A4%EC%8A%B5en\">Word2Vec 실습(EN)</a></p>\n<ul>\n<li><a href=\"/Pytorch07/#%ED%9B%88%EB%A0%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0\">훈련 데이터</a></li>\n<li><a href=\"/Pytorch07/#%EC%A0%84%EC%B2%98%EB%A6%AC\">전처리</a></li>\n<li><a href=\"/Pytorch07/#word2vec-%ED%95%99%EC%8A%B5\">Word2Vec 학습</a></li>\n<li><a href=\"/Pytorch07/#%EB%AA%A8%EB%8D%B8-%EC%A0%80%EC%9E%A5-%EB%A1%9C%EB%93%9C\">모델 저장, 로드</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/Pytorch07/"},"frontmatter":{"title":"자연어 처리(NLP)의 전처리 - Word2Vec(워드투벡터) 실습","date":"May 29, 2021","tags":["Pytorch"],"keywords":["Pytorch","Deep Learning","Machine Learning","NLP","Natural Language Processing","머신러닝","딥러닝","자연어 처리","Word2Vec","워드투벡터","분산 표현"],"update":"Jan 01, 0001"}}},"pageContext":{"slug":"/Pytorch07/","series":[],"lastmod":"0001-01-01"}},"staticQueryHashes":["3649515864","63159454"]}