{"componentChunkName":"component---src-templates-post-tsx","path":"/Pytorch04/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"원-핫-인코딩one-hot-encoding\" style=\"position:relative;\"><a href=\"#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9one-hot-encoding\" aria-label=\"원 핫 인코딩one hot encoding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>원-핫 인코딩(One-Hot Encoding)</h2>\n<p>지난 게시물인 <a href=\"https://mintyu.github.io/Pytorch03/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">정수 인코딩</a>에서는 Vocabulary의 각 단어에 인덱스를 부여하는 정수 인코딩까지 마쳤습니다. 그리고 이후 원-핫 인코딩과 워드 임베딩을 통해 단어들을 벡터로 바꿔준다고 말미에 언급했었습니다. 이번 게시물은 그 중 \"원-핫 인코딩(One-Hot Encoding)\"에 대한 내용입니다.</p>\n<h3 id=\"원-핫-인코딩이란\" style=\"position:relative;\"><a href=\"#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9%EC%9D%B4%EB%9E%80\" aria-label=\"원 핫 인코딩이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>원-핫 인코딩이란?</h3>\n<p>원-핫 인코딩이란, 단어 집합의 크기를 차원으로 하고 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. 이렇게 표현된 벡터의 이름이 원-핫 벡터(One-Hot Vector)입니다. 여기서 단어의 인덱스는 앞서 정수 인코딩을 통해 맵핑한 데이터를 기반으로 합니다.</p>\n<p>예시로, <code class=\"language-text\">&quot;자연어 전처리 과정입니다.&quot;</code> 라는 한글로 된 문장을 원-핫 벡터로 만드는 과정을 보겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Okt  \nokt <span class=\"token operator\">=</span> Okt<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  \ntoken <span class=\"token operator\">=</span> okt<span class=\"token punctuation\">.</span>morphs<span class=\"token punctuation\">(</span><span class=\"token string\">\"자연어 전처리 과정입니다.\"</span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">konlpy</code> 모듈의 <code class=\"language-text\">Okt</code> 형태소 분석기를 통해 문장에 대해 토큰화를 수행하는 과정입니다.</p>\n<p>이 과정에서 <code class=\"language-text\">konlpy</code> 모듈이 설치되지 않았다면 <code class=\"language-text\">$pip install konlpy</code> 명령어를 통해 설치해주시면 되고, 실행 과정에서 No JVM 오류가 발생한다면 JVM 설치를 진행해주시면 됩니다. 필자의 경우 도커 컨테이너 상에서 실습을 진행하고 있기에 <code class=\"language-text\">$apt install default-jdk</code>를 통해 설치를 진행했습니다. (각자의 운영체제 상황에 맞는 설치 방법으로 설치하시면 됩니다.)</p>\n<p>실행 결과는 다음과 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/be6ff415d1ee07fe3c57a37e90718c5f/7131f/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 10.81081081081081%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZklEQVQI11WNSQoAIQwE5yUqrqjgghv+/2E9JIeBuaaqOo9zDnNO3HuRc4YQAmMMWGtB7JyDEAKUUlhroffOTmuNu5QSM3LJeygkae/9wVIKvPfQWvOdRCnlb7DWys9ijNwYY7h5AcKLO5tNAAy9AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/be6ff415d1ee07fe3c57a37e90718c5f/fcda8/1.png\"\n        srcset=\"/static/be6ff415d1ee07fe3c57a37e90718c5f/12f09/1.png 148w,\n/static/be6ff415d1ee07fe3c57a37e90718c5f/e4a3f/1.png 295w,\n/static/be6ff415d1ee07fe3c57a37e90718c5f/fcda8/1.png 590w,\n/static/be6ff415d1ee07fe3c57a37e90718c5f/7131f/1.png 710w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>그리고 아래와 같이 각 토큰에 대해 인덱스를 부여해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">word2index <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">for</span> voca <span class=\"token keyword\">in</span> token<span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">if</span> voca <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> word2index<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       word2index<span class=\"token punctuation\">[</span>voca<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word2index<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>word2index<span class=\"token punctuation\">)</span></code></pre></div>\n<p>결과는 다음과 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f1f833b1a3dffb048e41ba4c2f11f3a2/b12f7/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.108108108108107%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAXElEQVQI102NWwoAIQwDPUrFJyooVrz/zbKkIOxXmjBDXc4ZrTUw11qIMcJ7jzkn9t4IISClZMy9F6UU68xzDsYY5rDTcxR67ybWWg0mwPvthP8P2ZmqatzjRQQfao86k7GQkAAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/f1f833b1a3dffb048e41ba4c2f11f3a2/fcda8/2.png\"\n        srcset=\"/static/f1f833b1a3dffb048e41ba4c2f11f3a2/12f09/2.png 148w,\n/static/f1f833b1a3dffb048e41ba4c2f11f3a2/e4a3f/2.png 295w,\n/static/f1f833b1a3dffb048e41ba4c2f11f3a2/fcda8/2.png 590w,\n/static/f1f833b1a3dffb048e41ba4c2f11f3a2/efc66/2.png 885w,\n/static/f1f833b1a3dffb048e41ba4c2f11f3a2/b12f7/2.png 1020w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">one_hot_encoding</span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> word2index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    one_hot_vector <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word2index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    index <span class=\"token operator\">=</span> word2index<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span>\n    one_hot_vector<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">return</span> one_hot_vector</code></pre></div>\n<p>위는 토큰을 입력하면 그에 해당하는 원-핫 벡터를 반환해주는 <code class=\"language-text\">one_hot_encoding</code>함수입니다.</p>\n<p>다음과 같이 토큰을 통해 함수를 호출하면, 원-핫 벡터를 얻을 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">one_hot_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"자연어\"</span><span class=\"token punctuation\">,</span>word2index<span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 328px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b213d23037aa6be243a8dc7872ea1b1c/d5c60/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.72972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAz0lEQVQY022RuwqFMBBE/QcRfL8q7axEEbUQVBSxVOz9/0+Yy6xEJNxi5OxkslkTIwxDBEEgIn/19f6t/8sb/MRx/DalPM+D7/sSIlNk13XFVxnl06OiKIJBaNsW8zwjTVMxr+tCURSwLAvHcaCua5imifM80TSN8LZtGIZBuO973PeNPM+fhlVVYZomCSdJgnVdMY6jTESmyMuySI6Zruuw77sMUZalHJZl2fPLamxOx9q2bfFYk+np7DjOu4eHseYe43vh+iN8fdVIf0CdfzUwrKjWP/eRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"3\"\n        title=\"3\"\n        src=\"/static/b213d23037aa6be243a8dc7872ea1b1c/d5c60/3.png\"\n        srcset=\"/static/b213d23037aa6be243a8dc7872ea1b1c/12f09/3.png 148w,\n/static/b213d23037aa6be243a8dc7872ea1b1c/e4a3f/3.png 295w,\n/static/b213d23037aa6be243a8dc7872ea1b1c/d5c60/3.png 328w\"\n        sizes=\"(max-width: 328px) 100vw, 328px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>함수에 <code class=\"language-text\">&quot;자연어&quot;</code> 라는 토큰을 입력으로 넣었더니, <code class=\"language-text\">[1, 0, 0, 0, 0, 0]</code> 이라는 원-핫 벡터를 리턴했습니다.</p>\n<p>앞에서 <code class=\"language-text\">&quot;자연어&quot;</code> 토큰은 인덱스 0번으로 정수 인코딩이 되었으니, 해당하는 0번 인덱스만 1의 값을 갖는 원-핫 벡터가 나오게 됩니다.</p>\n<h3 id=\"원-핫-인코딩의-한계\" style=\"position:relative;\"><a href=\"#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9%EC%9D%98-%ED%95%9C%EA%B3%84\" aria-label=\"원 핫 인코딩의 한계 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>원-핫 인코딩의 한계</h3>\n<p>원-핫 인코딩과 같은 표현 방식은, 단어의 수가 늘어날 수록 벡터의 크기가 점점 커진다는 단점이 있습니다. 단어 집합(Vocabulary)의 크기가 곧 원-핫 벡터의 차수이기 때문에, 단어의 수가 많으면 벡터를 저장하는데 리소스가 많이 필요할 뿐만 아니라 연산에서도 불리합니다.</p>\n<p>또한, 원-핫 벡터는 단어의 유사도를 표현하지 못합니다. 원-핫 인코딩을 통해서는 <code class=\"language-text\">[&#39;오렌지&#39;, &#39;사과&#39;, &#39;개&#39;, &#39;고양이&#39;]</code> 이와 같은 단어 집합이 있을 때, 원-핫 인코딩을 거치면 <code class=\"language-text\">[1, 0, 0, 0]</code>, <code class=\"language-text\">[0, 1, 0, 0]</code>, <code class=\"language-text\">[0, 0, 1, 0]</code>, <code class=\"language-text\">[0, 0, 0, 1]</code> 의 4개의 벡터로 표현됩니다. 인간은 단어 집합을 보고 오렌지와 사과는 과일이며 개와 고양이는 동물이므로 서로 유사한 특징을 묶어낼 수 있지만, 원-핫 벡터로는 그런 내용들을 포함할 수 없습니다. 인간도 단어 집합을 모르는 상태에서 원-핫 벡터만 봐서는 무엇과 무엇이 서로 유사한지 전혀 알 수 없을 것입니다.</p>\n<p>따라서 단어 간 유사도까지 표현할 수 있는 워드 임베딩 방식인 Word2Vec을 많이 채택합니다.</p>","excerpt":"원-핫 인코딩(One-Hot Encoding) 지난 게시물인 정수 인코딩에서는 Vocabulary…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/Pytorch04/#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9one-hot-encoding\">원-핫 인코딩(One-Hot Encoding)</a></p>\n<ul>\n<li><a href=\"/Pytorch04/#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9%EC%9D%B4%EB%9E%80\">원-핫 인코딩이란?</a></li>\n<li><a href=\"/Pytorch04/#%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9%EC%9D%98-%ED%95%9C%EA%B3%84\">원-핫 인코딩의 한계</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/Pytorch04/"},"frontmatter":{"title":"자연어 처리(NLP)의 전처리 - 원-핫 인코딩","date":"Apr 25, 2021","tags":["Pytorch"],"keywords":["Pytorch","Deep Learning","Machine Learning","NLP","Natural Language Processing","머신러닝","딥러닝","자연어 처리","정수 인코딩","원-핫 인코딩","One-hot encoding"],"update":"Jan 01, 0001"}}},"pageContext":{"slug":"/Pytorch04/","series":[],"lastmod":"0001-01-01"}},"staticQueryHashes":["3649515864","63159454"]}