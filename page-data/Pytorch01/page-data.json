{"componentChunkName":"component---src-templates-post-tsx","path":"/Pytorch01/","result":{"data":{"markdownRemark":{"html":"<p>자연어 처리는 일반적으로 토큰화, 단어 집합 생성, 정수 인코딩, 패딩, 벡터화의 과정을 거치게 됩니다. pytorch를 통한 자연어 처리를 진행하기 전에, 이 일련의 과정들을 알아보도록 하겠습니다.</p>\n<h2 id=\"토큰화tokenization\" style=\"position:relative;\"><a href=\"#%ED%86%A0%ED%81%B0%ED%99%94tokenization\" aria-label=\"토큰화tokenization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>토큰화(Tokenization)</h2>\n<p>주어진 텍스트를 단어 또는 문자 단위로 자르는 것을 <strong>토큰화</strong>라고 합니다.</p>\n<h3 id=\"1-띄어쓰기로-토큰화\" style=\"position:relative;\"><a href=\"#1-%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0%EB%A1%9C-%ED%86%A0%ED%81%B0%ED%99%94\" aria-label=\"1 띄어쓰기로 토큰화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 띄어쓰기로 토큰화</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 전</span>\n<span class=\"token string\">\"It does not matter how slowly you go as long as you do not stop\"</span></code></pre></div>\n<br/>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 후</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'It'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'does'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'not'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'matter'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'how'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'slowly'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'you'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'go'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'as'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'long'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'as'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'you'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'do'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'not'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'stop'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<br/>\n영어의 경우, 띄어쓰기 단위로 토큰화를 진행해도 단어들 간에 구분이 명확하기 때문에 토큰화 작업이 수월합니다. 하지만, 한국어의 경우 조사, 접사 등으로 인해 단순 띄어쓰기 단위로 토큰화를 진행하게 되면 같은 단어일지라도 조사와 접사 때문에 다른 단어로 인식되기 때문에 단어 집합(vocabulary)의 크기가 지나치게 커지는 문제가 존재합니다. 따라서 한국어의 경우 토큰화 과정이 영어에 비해 더 까다롭다고 할 수 있습니다.\n<h3 id=\"2-형태소-토큰화\" style=\"position:relative;\"><a href=\"#2-%ED%98%95%ED%83%9C%EC%86%8C-%ED%86%A0%ED%81%B0%ED%99%94\" aria-label=\"2 형태소 토큰화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 형태소 토큰화</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 전</span>\n<span class=\"token string\">\"당신이 멈추지 않는 이상, 얼마나 천천히 가는지는 전혀 문제되지 않습니다\"</span></code></pre></div>\n<br/>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 후</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'당신'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'이'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'멈추'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'지'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'않'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'는'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'이상'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">','</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'얼마나'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'천천히'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'가'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'는지'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'는'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'전혀'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'문제'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'되'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'지'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'않'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'습니다'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<br/>\n앞서 언급했듯, 한글의 경우는 띄어쓰기 단위로만 토큰화하는 경우 한계가 있기 때문에 위와 같이 단어를 형태소로 분리하여 토큰화를 진행하면 같은 의미의 단어끼리 보다 더 정확히 묶을 수 있게 됩니다.\n<h3 id=\"3-문자-토큰화\" style=\"position:relative;\"><a href=\"#3-%EB%AC%B8%EC%9E%90-%ED%86%A0%ED%81%B0%ED%99%94\" aria-label=\"3 문자 토큰화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 문자 토큰화</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 전</span>\n<span class=\"token string\">\"A Dog Run back corner near spare bedrooms\"</span></code></pre></div>\n<br/>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 토큰화 후</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'D'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'g'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'R'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'u'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'k'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'s'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'p'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'d'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'m'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'s'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<br/>\n<p>띄어쓰기, 형태소 이외에도 문자 단위로 토큰화를 진행하게 되는 경우도 있습니다.</p>\n<h2 id=\"토큰화-도구\" style=\"position:relative;\"><a href=\"#%ED%86%A0%ED%81%B0%ED%99%94-%EB%8F%84%EA%B5%AC\" aria-label=\"토큰화 도구 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>토큰화 도구</h2>\n<p>영어의 경우 토큰화를 사용하는 도구로서 대표적으로 spaCy와 NLTK가 있습니다. 물론, 파이썬 기본 함수인 split으로 토큰화를 할 수도 있습니다.</p>\n<p>다음과 같은 문장이 있다고 가정해봅시다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">en_text <span class=\"token operator\">=</span> <span class=\"token string\">\"A Dog Run back corner near spare bedrooms\"</span></code></pre></div>\n<h3 id=\"1-spacy\" style=\"position:relative;\"><a href=\"#1-spacy\" aria-label=\"1 spacy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. spaCy</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> spacy\nspacy_en <span class=\"token operator\">=</span> spacy<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'en'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">tokenize</span><span class=\"token punctuation\">(</span>en_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>tok<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">for</span> tok <span class=\"token keyword\">in</span> spacy_en<span class=\"token punctuation\">.</span>tokenizer<span class=\"token punctuation\">(</span>en_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tokenize<span class=\"token punctuation\">(</span>en_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']</span></code></pre></div>\n<h3 id=\"2-nltk\" style=\"position:relative;\"><a href=\"#2-nltk\" aria-label=\"2 nltk permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. NLTK</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> nltk\nnltk<span class=\"token punctuation\">.</span>download<span class=\"token punctuation\">(</span><span class=\"token string\">'punkt'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">from</span> nltk<span class=\"token punctuation\">.</span>tokenize <span class=\"token keyword\">import</span> word_tokenize\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>word_tokenize<span class=\"token punctuation\">(</span>en_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']</span></code></pre></div>\n<h3 id=\"3-split\" style=\"position:relative;\"><a href=\"#3-split\" aria-label=\"3 split permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. split()</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>en_text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']</span></code></pre></div>","excerpt":"자연어 처리는 일반적으로 토큰화, 단어 집합 생성, 정수 인코딩, 패딩, 벡터화의 과정을 거치게 됩니다. pytorch를 통한 자연어 처리를 진행하기 전에, 이 일련의 과정들을 알아보도록 하겠습니다. 토큰화(Tokenization…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/Pytorch01/#%ED%86%A0%ED%81%B0%ED%99%94tokenization\">토큰화(Tokenization)</a></p>\n<ul>\n<li><a href=\"/Pytorch01/#1-%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0%EB%A1%9C-%ED%86%A0%ED%81%B0%ED%99%94\">1. 띄어쓰기로 토큰화</a></li>\n<li><a href=\"/Pytorch01/#2-%ED%98%95%ED%83%9C%EC%86%8C-%ED%86%A0%ED%81%B0%ED%99%94\">2. 형태소 토큰화</a></li>\n<li><a href=\"/Pytorch01/#3-%EB%AC%B8%EC%9E%90-%ED%86%A0%ED%81%B0%ED%99%94\">3. 문자 토큰화</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/Pytorch01/#%ED%86%A0%ED%81%B0%ED%99%94-%EB%8F%84%EA%B5%AC\">토큰화 도구</a></p>\n<ul>\n<li><a href=\"/Pytorch01/#1-spacy\">1. spaCy</a></li>\n<li><a href=\"/Pytorch01/#2-nltk\">2. NLTK</a></li>\n<li><a href=\"/Pytorch01/#3-split\">3. split()</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/Pytorch01/"},"frontmatter":{"title":"자연어 처리(NLP)의 전처리 - 토큰화","date":"Apr 07, 2021","tags":["Pytorch"],"keywords":["Pytorch","Deep Learning","Machine Learning","NLP","Natural Language Processing","머신러닝","딥러닝","자연어 처리","토큰화","Tokenize"],"update":"Jan 01, 0001"}}},"pageContext":{"slug":"/Pytorch01/","series":[],"lastmod":"0001-01-01"}},"staticQueryHashes":["3649515864","63159454"]}