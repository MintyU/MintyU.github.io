{"componentChunkName":"component---src-templates-post-tsx","path":"/LSTM/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"lstmlong-short-term-memory-실습\" style=\"position:relative;\"><a href=\"#lstmlong-short-term-memory-%EC%8B%A4%EC%8A%B5\" aria-label=\"lstmlong short term memory 실습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LSTM(Long Short Term Memory) 실습</h2>\n<p>Kaggle의 영화 리뷰에 대한 감정 예측 데이터셋에 대해 LSTM으로 자연어차리 실습을 해보도록 하겠습니다.</p>\n<p><a href=\"https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle 링크</a>를 통해 실습 데이터셋을 받을 수 있습니다.</p>\n<p>Data 탭에서 <code class=\"language-text\">train.tsv.zip</code>, <code class=\"language-text\">test.tsv.zip</code> 을 내려받아 압축을 풀면 각각 train set과 test set의 tsv 파일을 얻을 수 있습니다.</p>\n<p>해당 데이터셋에서 감정을 나타내는 label들의 의미는 다음과 같습니다.</p>\n<ul>\n<li>0 : negative</li>\n<li>1 : somewhat negative</li>\n<li>2 : neutral</li>\n<li>3 : somewhat positive</li>\n<li>4 : positive</li>\n</ul>\n<h3 id=\"데이터-가져오기\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0\" aria-label=\"데이터 가져오기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 가져오기</h3>\n<p>우선 실습에 필요한 library들을 불러옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> pyplot <span class=\"token keyword\">as</span> plt\nplt<span class=\"token punctuation\">.</span>style<span class=\"token punctuation\">.</span>use<span class=\"token punctuation\">(</span><span class=\"token string\">'dark_background'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> Tokenizer\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>sequence <span class=\"token keyword\">import</span> pad_sequences\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>np_utils <span class=\"token keyword\">import</span> to_categorical\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Dropout<span class=\"token punctuation\">,</span> Embedding<span class=\"token punctuation\">,</span> LSTM<span class=\"token punctuation\">,</span> GlobalMaxPooling1D<span class=\"token punctuation\">,</span> SpatialDropout1D</code></pre></div>\n<p><code class=\"language-text\">to_categorical</code>은 keras의 버전에 따라 </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>np_utils <span class=\"token keyword\">import</span> to_categorical</code></pre></div>\n<p>혹은</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> to_categorical</code></pre></div>\n<p>둘 중 동작하는 것으로 진행하면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df_train <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'train.tsv'</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'train set: {0}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>df_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf_train<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>우선 train 데이터셋을 불러왔습니다. tsv 파일이므로 <code class=\"language-text\">sep=&#39;\\t&#39;</code>옵션으로 데이터를 불러옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df_test <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'test.tsv'</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test set: {0}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>df_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf_test<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>마찬가지로, test 데이터셋도 불러와줍니다.</p>\n<h3 id=\"데이터-전처리\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 전처리</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">replace_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">r\"i'm\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'i am'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'re\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' are'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"let’s\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'let us'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'s\"</span><span class=\"token punctuation\">:</span>  <span class=\"token string\">' is'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'ve\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' have'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"can't\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'can not'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"cannot\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'can not'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"shan’t\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'shall not'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"n't\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' not'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'d\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' would'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'ll\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' will'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">r\"'scuse\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'excuse'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">','</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' ,'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'.'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' .'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'!'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' !'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'?'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' ?'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'\\s+'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">clean_text</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    text <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> replace_list<span class=\"token punctuation\">:</span>\n        text <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> replace_list<span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    text <span class=\"token operator\">=</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> text</code></pre></div>\n<p>원활한 학습을 위해 전처리를 진행해줍니다. <code class=\"language-text\">i&#39;m</code> 과 <code class=\"language-text\">i am</code>은 같은 단어이지만 다르게 인식될 수 있으므로 형태를 통일해주고, 단어 뒤에 문장 부호가 붙어있는 경우에도 다른 단어로 인식되므로 빈 칸을 추가하여 단어와 문장 부호가 서로 다른 단어로 인식될 수 있게끔 전처리를 해줍니다. 또한, 대문자와 소문자의 차이도 제거하기 위해 모든 단어의 글자들을 <code class=\"language-text\">.lower()</code>함수를 통해 소문자로 만들어 줍니다.</p>\n<p>아래 코드를 통해 적용해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X_train <span class=\"token operator\">=</span> df_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Phrase'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> p<span class=\"token punctuation\">:</span> clean_text<span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/>\n이제, corpus(말뭉치)에 있는 구문의 길이를 시각화해보겠습니다.\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">phrase_len <span class=\"token operator\">=</span> X_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> p<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmax_phrase_len <span class=\"token operator\">=</span> phrase_len<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'max phrase len: {0}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>max_phrase_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>phrase_len<span class=\"token punctuation\">,</span> alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> density <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'phrase len'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'probability'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span>alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.25</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">max phrase len: 53</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8aa599c5ed592dc8ea4ee26ea0ba2569/f6b72/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.37837837837837%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAABe0lEQVQ4y61Ua1PCMBBM+khfSQthivIUUMbKw///79a72CCt4Aj64aabuct277KJMMag0NpFlmUu0jR1cQ1fy5VlCZEohbIeYbZ7haKEEOLu0CRKqCjG4GGM5XGHtMg7BUEQQEr5DfOX1x774G6FLjQR1nh6J0JddArCMDwRnWP+8tpjH44wkAEG4xqLwxtU3m3ZK+rjS+tTy5UpW4X7/1EYEuAZssKkN8PfKvTYKczSDEM+FD9D8aXQK+rjazmnMI4i1/Li+HeFjlDF8Ymw78O7CI3+tA370NghFDleng3/5pYjOi2n8NBgTrdl8rLpGFvIGw/FaHNSuNg3mDVb5FWJmK6kK243/WQbn2uNLVGxsYmQFc6JlHG9XqKwA8RpQirlRSNfNDa/EJZsM91uMKV2l6Rw8rym1tdY7RpMNivY6aOrqUYWKd2mjNzAmxV1kdAP8zx32BFGZBsOPzN+fbwaLuKctRZ1XUMlCR2YRETO4CdLtDeIny6/5wPcYVllo8xn+QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/8aa599c5ed592dc8ea4ee26ea0ba2569/fcda8/1.png\"\n        srcset=\"/static/8aa599c5ed592dc8ea4ee26ea0ba2569/12f09/1.png 148w,\n/static/8aa599c5ed592dc8ea4ee26ea0ba2569/e4a3f/1.png 295w,\n/static/8aa599c5ed592dc8ea4ee26ea0ba2569/fcda8/1.png 590w,\n/static/8aa599c5ed592dc8ea4ee26ea0ba2569/f6b72/1.png 615w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>가장 긴 문장의 길이는 53이며, 단어 길이의 분포는 위와 같습니다.</p>\n<p>신경망에 대한 모든 입력은 길이가 같아야합니다. 따라서 가장 긴 길이를 나중에 모델에 대한 입력을 정의하는 데 사용할 변수로 저장합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">y_train = df_train[&#39;Sentiment&#39;]</code></pre></div>\n<p>감정 데이터가 있는 <code class=\"language-text\">Sentiment</code> 항목으로 train set을 만들어줍니다.</p>\n<p>이제 <code class=\"language-text\">tokenizer</code>를 통해 토큰화를 진행합니다.\n또한, <code class=\"language-text\">filters=</code> 옵션을 통해 특수문자들을 제거해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">max_words = 8192\ntokenizer = Tokenizer(\n    num_words = max_words,\n    filters = &#39;&quot;#$%&amp;()*+-/:;&lt;=&gt;@[\\]^_`{|}~&#39;\n)\ntokenizer.fit_on_texts(X_train)\nX_train = tokenizer.texts_to_sequences(X_train)\nX_train = pad_sequences(X_train, maxlen = max_phrase_len)\ny_train = to_categorical(y_train)</code></pre></div>\n<p><code class=\"language-text\">to_categorical</code> 함수를 통해, <code class=\"language-text\">y_train</code> 값을 원-핫 벡터로 바꿔주어 인코딩 과정도 진행해줍니다.</p>\n<h3 id=\"training\" style=\"position:relative;\"><a href=\"#training\" aria-label=\"training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model_lstm <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Embedding<span class=\"token punctuation\">(</span>input_dim <span class=\"token operator\">=</span> max_words<span class=\"token punctuation\">,</span> output_dim <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> input_length <span class=\"token operator\">=</span> max_phrase_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>SpatialDropout1D<span class=\"token punctuation\">(</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> recurrent_dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel_lstm<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\n    loss<span class=\"token operator\">=</span><span class=\"token string\">'categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n    optimizer<span class=\"token operator\">=</span><span class=\"token string\">'Adam'</span><span class=\"token punctuation\">,</span>\n    metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<p>LSTM 레이어를 만들어 모델을 작성합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">history <span class=\"token operator\">=</span> model_lstm<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\n    X_train<span class=\"token punctuation\">,</span>\n    y_train<span class=\"token punctuation\">,</span>\n    validation_split <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span>\n    batch_size <span class=\"token operator\">=</span> <span class=\"token number\">512</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">epochs</code>는 8, <code class=\"language-text\">batch_size</code>는 512로 설정하고 10%만큼을 validation set으로 이용하게 됩니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/08485/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.891891891891895%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAu0lEQVQoz5WSzQ6EIAyEef9nFGKQg3AS5cdbN9NkDLrZxD00BTr9aAtmnmdZ11W2bZPWmvTe1c7z1P1xHFJr1T1j2FNLjzjMWGvFey8xxiu5lKJCrHPOsu+7rhnHGTTUco0cBS7LIimlm4iVoHKAIOZFuIDaUQ/7C8gqRiD9DRhC+AlEeyMQ5xwBqx5napxzCsQM3wBZ4RPIy8w0TV8tM/gEjjMkkPoLiG/DlpHIV6MYMySAfnxl5kAP+wCPiWWuG6ZLQgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/fcda8/2.png\"\n        srcset=\"/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/12f09/2.png 148w,\n/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/e4a3f/2.png 295w,\n/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/fcda8/2.png 590w,\n/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/efc66/2.png 885w,\n/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/c83ae/2.png 1180w,\n/static/c3e4499203aa9a9c8ee9e77f1c49ffc0/08485/2.png 2014w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>train이 완료되었습니다. history에는 LSTM fitting 과정에서 각 epoch마다의 <code class=\"language-text\">loss</code>와 <code class=\"language-text\">accuracy</code> 데이터가 저장됩니다.</p>\n<p>loss와 accuracy 데이터를 시각화하면 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>clf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nval_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\nepochs <span class=\"token operator\">=</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">,</span> <span class=\"token string\">'g'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">,</span> val_loss<span class=\"token punctuation\">,</span> <span class=\"token string\">'y'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Validation loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Training and validation loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Epochs'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8602c6bc6d00b4be1354a70d420f812a/d0d8c/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 81.75675675675677%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAABWElEQVQ4y6WU227DIAyGDdhADl1UTdOiVO31+v4P6PFzSLs2q7r14o/B4C82JyIiFe91GAfd7XY6DIOGEFRENMaoy7Lo4XDQeZ71eDzm/jiOyszqUxzmMUuyPvVFCZ39+5t+fO71/HXW0+mUQfiRMWa1xlBtN7/JVsRo35sUYzKcrLXadVFZuP7Fr6DfBCgzpThK1ZBaW/zOOSUEI33ytGZxLeeKRAogxiKAbudnIDLq+0E5TerGJATcBMICCEDLZksZiE/woTilrdFFj0rfBOZdxmLC6f8G2ARO05RK7ouTq14Bdl13ydC8luV9yS1L/wIQtwK348egrVD+BzDvcgjbk/gKbJ8Elusjjye7cqRWuHsAxMHGxjxdmq1QqXKX7J2tJeMxgIVwDe/a7BR3vvnXseTnkGx0WT74sssYbFBY9LEMWFv4cE7xZMHmZysFtrEYYs4MFr5vpPRJZ12wigYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"3\"\n        title=\"3\"\n        src=\"/static/8602c6bc6d00b4be1354a70d420f812a/fcda8/3.png\"\n        srcset=\"/static/8602c6bc6d00b4be1354a70d420f812a/12f09/3.png 148w,\n/static/8602c6bc6d00b4be1354a70d420f812a/e4a3f/3.png 295w,\n/static/8602c6bc6d00b4be1354a70d420f812a/fcda8/3.png 590w,\n/static/8602c6bc6d00b4be1354a70d420f812a/d0d8c/3.png 609w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>clf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nval_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">,</span> <span class=\"token string\">'g'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training acc'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">,</span> val_acc<span class=\"token punctuation\">,</span> <span class=\"token string\">'y'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Validation acc'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Training and validation accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Epochs'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/99415847bcfe539595404742c9465c10/f6b72/4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 80.4054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAABTElEQVQ4y62U23LDIAxEhUHga+xeJpNkMpPX9v8/cMsCjt2maZukDztGyByvjECMMQghoO1aDMOAvu9T7JzDNE04HA7Y7/c4Ho9pvNvtsN1uEXyAqsKrhzrNY+8htrJ4fpnw9Nrj7e0dp9MpAUUE/JiY8oxxmhOTZYs0qo55Lwh1WidomibS81eoNeBCNkpXYmxyjm7FWouu664DqKosji7ELYCvSiXTDR1+68oWiBao/Kz8D6NDbsbFCzNI/q4ErKoKbdt+Li9cL+tX4DiOqOt6KdnfBzsD2Wt0yFZIIL0PdgbObZOAtuziI0D23WazWcqVf3CYd8ckd9Yyvk2qFw5H2JhoBkEd8gu3iNAQqOJQ45FxraCyj5VMc8khd1ojnTfM+kxnuVQK+5X59dwS57nSz0v9PDXzM8MziH3KfuUCzjPPG4k5wuZ1HH8AjBBKy/tCbqwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"4\"\n        title=\"4\"\n        src=\"/static/99415847bcfe539595404742c9465c10/fcda8/4.png\"\n        srcset=\"/static/99415847bcfe539595404742c9465c10/12f09/4.png 148w,\n/static/99415847bcfe539595404742c9465c10/e4a3f/4.png 295w,\n/static/99415847bcfe539595404742c9465c10/fcda8/4.png 590w,\n/static/99415847bcfe539595404742c9465c10/f6b72/4.png 615w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>","excerpt":"LSTM(Long Short Term Memory) 실습 Kaggle의 영화 리뷰에 대한 감정 예측 데이터셋에 대해 LSTM으로 자연어차리 실습을 해보도록 하겠습니다. Kaggle 링크를 통해 실습 데이터셋을 받을 수 있습니다. Data…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/LSTM/#lstmlong-short-term-memory-%EC%8B%A4%EC%8A%B5\">LSTM(Long Short Term Memory) 실습</a></p>\n<ul>\n<li><a href=\"/LSTM/#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0\">데이터 가져오기</a></li>\n<li><a href=\"/LSTM/#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">데이터 전처리</a></li>\n<li><a href=\"/LSTM/#training\">Training</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/LSTM/"},"frontmatter":{"title":"자연어 처리(NLP) 실습 - LSTM","date":"Jun 07, 2021","tags":["ML"],"keywords":["Deep Learning","Machine Learning","NLP","Natural Language Processing","머신러닝","딥러닝","자연어 처리","토큰화","Tokenize","LSTM"],"update":"Jan 01, 0001"}}},"pageContext":{"slug":"/LSTM/","series":[],"lastmod":"0001-01-01"}},"staticQueryHashes":["3649515864","63159454"]}