{"componentChunkName":"component---src-templates-post-tsx","path":"/Pytorch02/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"단어-집합vocabulary-생성\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%96%B4-%EC%A7%91%ED%95%A9vocabulary-%EC%83%9D%EC%84%B1\" aria-label=\"단어 집합vocabulary 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단어 집합(Vocabulary) 생성</h2>\n<p>단어 집합(vocabuary)이란 중복을 제거한 텍스트의 총 단어의 집합(set)을 의미합니다. 우선, 실습을 위해서 깃허브에서 '네이버 영화 리뷰 분류하기' 데이터를 다운로드하겠습니다. 네이버 영화 리뷰 데이터는 총 20만 개의 영화 리뷰를 긍정 1, 부정 0으로 레이블링한 데이터입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> urllib<span class=\"token punctuation\">.</span>request\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Mecab\n<span class=\"token keyword\">from</span> nltk <span class=\"token keyword\">import</span> FreqDist\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nurllib<span class=\"token punctuation\">.</span>request<span class=\"token punctuation\">.</span>urlretrieve<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\"</span><span class=\"token punctuation\">,</span> filename<span class=\"token operator\">=</span><span class=\"token string\">\"ratings.txt\"</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_table<span class=\"token punctuation\">(</span><span class=\"token string\">'ratings.txt'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 데이터프레임에 저장</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5de8ef94b25fd87cd1611b2e989f91bc/46115/1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAABGUlEQVQoz3WSZ4rFMAyEfY/03nsjIYHc/1JaPoMe7GP3xyBblkYjySYIAqnrWtI0Fc/zxPf9fxGGocRxbC15eZ7LeZ4yTZPM8yxlWYpZlkXu+5aqqqxDURSFTeCMBeM4yvM8sq6rJTqOQ973lWEYbDwwXdcJpCTygNqmaQQ/BFTu+/5jIQP7vltl5CRJIo7jSBRFYtq2tQG0ALQlJVQy4rhrexARA1DPuMg1PCKdKjyoQhKYK20oCW2iDAFKyJkYCOEwGogqZLuua60iy7JfZBTnThF8nMFHIS3xQLvfW9aqkOooWN62bXbuqpBREG8V0h7Vvgn1jEoWpvNU6Bw5Y4m1S+FyXZe9/PUP8VEMdfr/8OsS9T9iUfgDF24JbBW1d5cAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/5de8ef94b25fd87cd1611b2e989f91bc/fcda8/1.png\"\n        srcset=\"/static/5de8ef94b25fd87cd1611b2e989f91bc/12f09/1.png 148w,\n/static/5de8ef94b25fd87cd1611b2e989f91bc/e4a3f/1.png 295w,\n/static/5de8ef94b25fd87cd1611b2e989f91bc/fcda8/1.png 590w,\n/static/5de8ef94b25fd87cd1611b2e989f91bc/efc66/1.png 885w,\n/static/5de8ef94b25fd87cd1611b2e989f91bc/c83ae/1.png 1180w,\n/static/5de8ef94b25fd87cd1611b2e989f91bc/46115/1.png 1290w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'전체 샘플의 수 : {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 전체 샘플의 수 : 200000</span></code></pre></div>\n<br/>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sample_data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 임의로 100개만 저장</span></code></pre></div>\n<br/>\n<p>아래와 같이 정규 표현식을 통해 데이터를 정제하는 과정을 거칩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sample_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> sample_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\nsample_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e43d677c95e027ed4b8fbebfb682be77/874d1/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.24324324324324%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAABEUlEQVQoz2WRV27AMAxDfY3svZG9kHzk/rdS8QwoaNMPQpZlUpRswjCUoigsgiAQ8i+iKPoXeQvnPE/p+16WZZE0TcUMwyDXdUnXdVKWpVRVZaNCm2VZJtM0yX3fsm2bFTqOQ57nsVzAG8Nh33dpmkbGcXyLbdvaHBGaEoEKEXGFeJIk1nEcx2Igcok6BaBnhNd1tcKQEQbaCHCPGdYAx1CkG6NSUGeIQa7r2u6IN0yCO+oAIzSk/grqDnHluq74vi+e59noOI7d3zzP76i81VFVEPFXUEfmh76/TM59nuc2QmIKBAHOEGSaV5CEzjj8LahnIm4hA92j7pC7P4J0pAsuIH4d6pkfhECETNQza9H8B5qVCIsVdhpqAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/e43d677c95e027ed4b8fbebfb682be77/fcda8/2.png\"\n        srcset=\"/static/e43d677c95e027ed4b8fbebfb682be77/12f09/2.png 148w,\n/static/e43d677c95e027ed4b8fbebfb682be77/e4a3f/2.png 295w,\n/static/e43d677c95e027ed4b8fbebfb682be77/fcda8/2.png 590w,\n/static/e43d677c95e027ed4b8fbebfb682be77/efc66/2.png 885w,\n/static/e43d677c95e027ed4b8fbebfb682be77/c83ae/2.png 1180w,\n/static/e43d677c95e027ed4b8fbebfb682be77/874d1/2.png 1310w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>그 다음은 토큰화를 수행하기에 앞서, 불용어(Stopword)를 제거하기 위해 불용어를 임의로 정해주었습니다.</p>\n<p>불용어란, 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들을 말합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">stopwords<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'의'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'가'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'이'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'은'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'들'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'는'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'좀'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'잘'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'걍'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'과'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'도'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'를'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'으로'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'자'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'에'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'와'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'한'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'하다'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<br/>\n<p>형태소 분석기는 Mecab을 사용합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tokenizer <span class=\"token operator\">=</span> Mecab<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ntokenized<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> sample_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    temp <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>morphs<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 토큰화</span>\n    temp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>word <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> temp <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> word <span class=\"token keyword\">in</span> stopwords<span class=\"token punctuation\">]</span> <span class=\"token comment\"># 불용어 제거</span>\n    tokenized<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tokenized<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9563775cb04754443c39d32054e13ff8/df438/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 24.324324324324326%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAs0lEQVQY0z2QWwrFIAxEXUoptEjp01oVW8H9byqXE8j9CI6TyWTUpZRk33c5jkNCCOK9l/M89Q7/PI9s2yborutSfl1XxTFG1YBLKTIMg7j7vlUMwYkpJhTDrTXlc87/PgtrrdJ7VzM80IMdTTOhAWYQjMAG0MFzkgqOJbaAeV7nABDf96kQTFqeY8ZgSw3GBDPTvO+reBxHcfZXiPgrEmFqae2ODgyHHoNlWbSmadKa51l+6lOd5w1o3yMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"3\"\n        title=\"3\"\n        src=\"/static/9563775cb04754443c39d32054e13ff8/fcda8/3.png\"\n        srcset=\"/static/9563775cb04754443c39d32054e13ff8/12f09/3.png 148w,\n/static/9563775cb04754443c39d32054e13ff8/e4a3f/3.png 295w,\n/static/9563775cb04754443c39d32054e13ff8/fcda8/3.png 590w,\n/static/9563775cb04754443c39d32054e13ff8/efc66/3.png 885w,\n/static/9563775cb04754443c39d32054e13ff8/c83ae/3.png 1180w,\n/static/9563775cb04754443c39d32054e13ff8/df438/3.png 1556w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>이제 단어집합(Vocabulary)을 생성합니다. NLTK에서는 빈도수 계산 도구인 FreqDist()를 지원합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">vocab <span class=\"token operator\">=</span> FreqDist<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>hstack<span class=\"token punctuation\">(</span>tokenized<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'단어 집합의 크기 : {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 단어 집합의 크기 : 664</span></code></pre></div>\n<br/>\n<p><code class=\"language-text\">vocab</code>에는 단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장됩니다. 다음과 같이 vocab에 단어를 입력하면 등장한 빈도수를 리턴합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'재밌'</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># 10</span></code></pre></div>\n<br/>\n<p>만약 vocab의 사이즈를 원하는대로 조정하고싶다면, <code class=\"language-text\">.most_common()</code>을 통해 할 수 있습니다. 예시는 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">vocab_size <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\nvocab <span class=\"token operator\">=</span> vocab<span class=\"token punctuation\">.</span>most_common<span class=\"token punctuation\">(</span>vocab_size<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'단어 집합의 크기 : {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 단어 집합의 크기 : 100</span></code></pre></div>","excerpt":"단어 집합(Vocabulary) 생성 단어 집합(vocabuary)이란 중복을 제거한 텍스트의 총 단어의 집합(set…","tableOfContents":"<ul>\n<li><a href=\"/Pytorch02/#%EB%8B%A8%EC%96%B4-%EC%A7%91%ED%95%A9vocabulary-%EC%83%9D%EC%84%B1\">단어 집합(Vocabulary) 생성</a></li>\n</ul>","fields":{"slug":"/Pytorch02/"},"frontmatter":{"title":"자연어 처리(NLP)의 전처리 - 단어 집합 생성","date":"Apr 13, 2021","tags":["Pytorch"],"keywords":["Pytorch","Deep Learning","Machine Learning","NLP","Natural Language Processing","머신러닝","딥러닝","자연어 처리","단어 집합 생성","Vocabulary"],"update":"Jan 01, 0001"}}},"pageContext":{"slug":"/Pytorch02/","series":[],"lastmod":"0001-01-01"}},"staticQueryHashes":["3649515864","63159454"]}